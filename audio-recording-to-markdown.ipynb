{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/galenchen/audio-recording-to-markdown?scriptVersionId=167019294\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"b3b39e62","metadata":{"papermill":{"duration":0.003171,"end_time":"2024-03-14T16:10:24.013154","exception":false,"start_time":"2024-03-14T16:10:24.009983","status":"completed"},"tags":[]},"source":["# Python Script for Automated Audio Transcription and Text Organization\n","\n","This Python script is designed to automate the process of downloading audio files, transcribing them, organizing the transcriptions into markdown format, and then sending these organized texts via email. This guide will help you understand how to use the script, its requirements, and how to customize it for your needs.\n","\n","## Prerequisites\n","\n","- Python 3 environment (The code has been tested in a Kaggle Python environment)\n","- Installed libraries: `openai-whisper`, `google-generativeai`, `gdown`, `gspread`, `oauth2client`, `gspread_dataframe`, and other standard libraries like `os`, `numpy`, `pandas`, etc.\n","- A Kaggle account (for Kaggle Secrets) or access to API keys and service accounts for Google Sheets, Google Drive, SMTP server for email, and Google's Generative AI service.\n","- Google Sheets for storing links to audio files and configuration parameters.\n","- For example: [This Google Sheet](https://docs.google.com/spreadsheets/d/1SGzPdPSJdxxKHX2cx2bMjnKeveaOXtwT0q1w1x5YO80/edit?usp=sharing) is used to control this kaggle notebook that excutes every day. If the code finds new files, it will do the audio to markdown notes conversion.\n","\n","## Installation\n","\n","1. Ensure that you have Python 3.x installed on your machine.\n","2. Install the required Python packages by running the following commands in your terminal:\n","\n","\n","```bash\n","pip install openai-whisper google-generativeai gdown gspread oauth2client gspread_dataframe\n","```\n","\n","3. Clone or download the script from the provided source (not applicable here; follow instructions from where you found this README).\n","\n","## Setting Up Your Environment\n","\n","1. **Google Sheets Authentication**: You need to create a service account on Google Cloud, download the JSON key, and place it securely in your project. This key will be used to access Google Sheets where your audio file links and parameters are stored.\n","\n","2. **API Keys**: Obtain the necessary API keys for Whisper (for audio transcription), Google's Generative AI service (for organizing text), and any other service you're using.\n","\n","3. **Secrets**: If you're running this script in an environment that supports secrets (like Kaggle), add your API keys and service account information as secrets. Otherwise, ensure they are securely stored and accessed within your script.\n","\n","## Configuration\n","\n","Before running the script, perform the following configurations:\n","1. **Google Sheets and Drive Authentication**:\n","   - Create a Google Cloud service account.\n","   - Download the JSON key for the service account.\n","   - Load the JSON key into the script to authenticate with Google Sheets and Drive.\n","\n","\n","2. **API Keys and Secrets**:\n","   - Use Kaggle Secrets or a secure method to store and access your API keys for Google's Generative AI and SMTP credentials for sending emails.\n","\n","\n","3. **Google Sheets Setup**:\n","   - Prepare two Google Sheets:\n","     1. The first sheet stores the links to the audio files to be downloaded and transcribed.\n","     2. The second sheet contains configuration parameters for transcription and text organization, such as model names, language settings, and API keys.\n","   - You must configure these sheets according to your needs. Refer to [this Google sheet](https://docs.google.com/spreadsheets/d/1SGzPdPSJdxxKHX2cx2bMjnKeveaOXtwT0q1w1x5YO80/edit?usp=sharing) for details on how to structure your sheets.\n","\n","\n","4. **Email SMTP Server**:\n","   - Configure your SMTP server details for sending emails with the organized markdown files as attachments.\n","\n","\n","## Running the Script\n","To execute the script, simply run it in your Python environment. The script will automatically:\n","1. Download audio files from the links provided in the Google Sheet.\n","2. Transcribe audio files using OpenAI's Whisper model.\n","3. Organize the transcribed text into markdown format using Google's Generative AI.\n","4. Email the organized markdown files to the specified recipient.\n","Make sure your environment variables, API keys, and Google Sheets are correctly set up and accessible by the script.\n","\n","## Customization\n","The script functions are modular, allowing you to modify specific processes, such as how files are downloaded, the transcription process, or the text organization algorithm. You can adjust parameters within the Google Sheet or modify the script directly to meet your specific requirements.\n","\n","## Troubleshooting\n","If you encounter any issues, check the following:\n","- Ensure all dependencies are installed.\n","- Verify your API keys and service accounts are correctly set up and have the necessary permissions.\n","- Check your Google Sheets for correct formatting and data.\n","\n","## Conclusion\n","This script automates a comprehensive workflow for processing audio files, making it a valuable tool for anyone needing to transcribe and organize audio content efficiently. Customize it to fit your project, and enjoy streamlined audio processing!"]},{"cell_type":"code","execution_count":1,"id":"c651f432","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-14T16:10:24.019684Z","iopub.status.busy":"2024-03-14T16:10:24.01936Z","iopub.status.idle":"2024-03-14T16:11:53.763932Z","shell.execute_reply":"2024-03-14T16:11:53.762786Z"},"papermill":{"duration":89.750449,"end_time":"2024-03-14T16:11:53.766183","exception":false,"start_time":"2024-03-14T16:10:24.015734","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai-whisper\r\n","  Downloading openai-whisper-20231117.tar.gz (798 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n","\u001b[?25hCollecting triton<3,>=2.0.0 (from openai-whisper)\r\n","  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n","Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (0.58.1)\r\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (1.26.4)\r\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (2.1.2)\r\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (4.66.1)\r\n","Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (10.2.0)\r\n","Collecting tiktoken (from openai-whisper)\r\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\r\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper) (0.41.1)\r\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2023.12.25)\r\n","Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.31.0)\r\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (4.9.0)\r\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (1.12)\r\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.2.1)\r\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.2)\r\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (2024.2.0)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.18)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.3)\r\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\r\n","Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hBuilding wheels for collected packages: openai-whisper\r\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n","\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=f895456ab2c0ec40da75224b70ae19e628fd16f2b8760dc9668a1f14130a91c9\r\n","  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\r\n","Successfully built openai-whisper\r\n","Installing collected packages: triton, tiktoken, openai-whisper\r\n","Successfully installed openai-whisper-20231117 tiktoken-0.6.0 triton-2.2.0\r\n","Requirement already satisfied: google-generativeai in /opt/conda/lib/python3.10/site-packages (0.3.2)\r\n","Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (0.4.0)\r\n","Requirement already satisfied: google-auth in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.26.1)\r\n","Requirement already satisfied: google-api-core in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.11.1)\r\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.9.0)\r\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (3.20.3)\r\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.66.1)\r\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.23.0)\r\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.62.0)\r\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.31.0)\r\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth->google-generativeai) (4.2.4)\r\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth->google-generativeai) (0.3.0)\r\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth->google-generativeai) (4.9)\r\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai) (1.51.1)\r\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai) (1.48.1)\r\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.5.1)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.18)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\r\n","Collecting gdown\r\n","  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\r\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\r\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\r\n","Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\r\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\r\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\r\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\r\n","Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\r\n","Installing collected packages: gdown\r\n","Successfully installed gdown-5.1.0\r\n","Collecting gspread\r\n","  Downloading gspread-6.0.2-py3-none-any.whl.metadata (10 kB)\r\n","Requirement already satisfied: oauth2client in /opt/conda/lib/python3.10/site-packages (4.1.3)\r\n","Requirement already satisfied: google-auth>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from gspread) (2.26.1)\r\n","Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from gspread) (1.2.0)\r\n","Collecting StrEnum==0.4.15 (from gspread)\r\n","  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\r\n","Requirement already satisfied: httplib2>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from oauth2client) (0.21.0)\r\n","Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client) (0.5.1)\r\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client) (0.3.0)\r\n","Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client) (4.9)\r\n","Requirement already satisfied: six>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from oauth2client) (1.16.0)\r\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread) (4.2.4)\r\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\r\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2>=0.9.1->oauth2client) (3.1.1)\r\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\r\n","Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.31.0)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.6)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (1.26.18)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2024.2.2)\r\n","Downloading gspread-6.0.2-py3-none-any.whl (53 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\r\n","Installing collected packages: StrEnum, gspread\r\n","Successfully installed StrEnum-0.4.15 gspread-6.0.2\r\n","Collecting gspread_dataframe\r\n","  Downloading gspread_dataframe-3.3.1-py2.py3-none-any.whl.metadata (4.1 kB)\r\n","Requirement already satisfied: gspread>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from gspread_dataframe) (6.0.2)\r\n","Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from gspread_dataframe) (2.1.4)\r\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from gspread_dataframe) (1.16.0)\r\n","Requirement already satisfied: google-auth>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from gspread>=3.0.0->gspread_dataframe) (2.26.1)\r\n","Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from gspread>=3.0.0->gspread_dataframe) (1.2.0)\r\n","Requirement already satisfied: StrEnum==0.4.15 in /opt/conda/lib/python3.10/site-packages (from gspread>=3.0.0->gspread_dataframe) (0.4.15)\r\n","Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->gspread_dataframe) (1.26.4)\r\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->gspread_dataframe) (2.8.2)\r\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->gspread_dataframe) (2023.3.post1)\r\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->gspread_dataframe) (2023.4)\r\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread_dataframe) (4.2.4)\r\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread_dataframe) (0.3.0)\r\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread>=3.0.0->gspread_dataframe) (4.9)\r\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (1.3.1)\r\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread>=3.0.0->gspread_dataframe) (0.5.1)\r\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (3.2.2)\r\n","Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (2.31.0)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (3.3.2)\r\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (3.6)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (1.26.18)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.0.0->gspread_dataframe) (2024.2.2)\r\n","Downloading gspread_dataframe-3.3.1-py2.py3-none-any.whl (8.0 kB)\r\n","Installing collected packages: gspread_dataframe\r\n","Successfully installed gspread_dataframe-3.3.1\r\n","\n","Installation and import completed.\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","!pip install openai-whisper\n","!pip install google-generativeai\n","!pip install gdown\n","!pip install gspread oauth2client\n","!pip install gspread_dataframe\n","\n","import os\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import shutil\n","import whisper\n","import google.generativeai as genai\n","from pathlib import Path\n","import gdown\n","import requests\n","from datetime import datetime\n","\n","import smtplib\n","from email.mime.multipart import MIMEMultipart\n","from email.mime.base import MIMEBase\n","from email.mime.text import MIMEText\n","from email import encoders\n","\n","from kaggle_secrets import UserSecretsClient # These values should be kept secret.\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"gcp_gsheets\")\n","secret_value_1 = user_secrets.get_secret(\"gemini_api\")\n","secret_value_2 = user_secrets.get_secret(\"gmail_smtp\")\n","secret_value_3 = user_secrets.get_secret(\"gmail_username\")\n","\n","import gspread\n","from oauth2client.service_account import ServiceAccountCredentials\n","from gspread_dataframe import get_as_dataframe\n","\n","import json\n","\n","# Since the secret is in string format, convert it back to a dictionary\n","service_account_info = json.loads(secret_value_0)\n","\n","# Use this dictionary to authenticate\n","scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n","creds = ServiceAccountCredentials.from_json_keyfile_dict(service_account_info, scope)\n","client = gspread.authorize(creds)\n","\n","print()\n","print(\"Installation and import completed.\")"]},{"cell_type":"code","execution_count":2,"id":"37462902","metadata":{"execution":{"iopub.execute_input":"2024-03-14T16:11:53.788075Z","iopub.status.busy":"2024-03-14T16:11:53.787562Z","iopub.status.idle":"2024-03-14T16:11:53.826487Z","shell.execute_reply":"2024-03-14T16:11:53.825624Z"},"papermill":{"duration":0.052298,"end_time":"2024-03-14T16:11:53.82849","exception":false,"start_time":"2024-03-14T16:11:53.776192","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","All functions loaded.\n"]}],"source":["def gdown_download(dataset_directory, df):\n","    errors = []  # List to store error messages\n","    for index, row in df.iterrows():\n","        google_drive_link = row['Google Drive Link of Files']\n","        file_name_provided = row.get('File name')  # Get the file name if provided\n","        \n","        if pd.isna(file_name_provided):\n","            # Skip this file and record an error if file name is not provided\n","            errors.append(f\"File name not provided for link at row {index+1}. Skipping download.\")\n","            continue\n","        \n","        try:\n","            # Try to extract the file ID from the link\n","            file_id = google_drive_link.split('/d/')[1].split('/')[0]\n","        except IndexError:\n","            errors.append(f\"Could not extract file ID from link at row {index+1}. Skipping download.\")\n","            continue\n","        \n","        # Construct the Google Drive download URL\n","        download_url = f\"https://drive.google.com/uc?id={file_id}\"\n","        \n","        filename = file_name_provided  # Use the provided file name\n","        \n","        # Define the output path\n","        output_path = f\"{dataset_directory}/{filename}\"\n","        \n","        # Download the file using gdown\n","        try:\n","            gdown.download(download_url, output_path, quiet=False)\n","            print(f\"File {index+1} has been downloaded and saved to: {output_path}\")\n","        except Exception as e:\n","            errors.append(f\"Error downloading file at row {index+1}: {str(e)}\")\n","\n","    # Check for errors and print them\n","    if errors:\n","        for error in errors:\n","            print(error)\n","    else:\n","        print(\"All files with provided names have been successfully downloaded.\")\n","    \n","\n","def transcribe_audio_files(dataset_directory, model_name=\"base\", language=\"en\", without_timestamps=True):\n","    base_output_directory = Path(f\"{dataset_directory}/transcribed_files\")\n","    os.makedirs(base_output_directory, exist_ok=True)\n","\n","    print(f\"Loading model '{model_name}'...\")\n","    whisper_model = whisper.load_model(model_name)\n","\n","    for root, dirs, files in os.walk(dataset_directory):\n","        for file in files:\n","            if file.endswith((\".mp3\", \".wav\", \".flac\", \".m4a\")):\n","                audio_path = os.path.join(root, file)\n","                print(f\"Transcribing {audio_path} with model '{model_name}' in {language}...\")\n","                \n","                # Perform transcription without timestamps\n","                print(\"Transcribing...\")\n","                result = whisper_model.transcribe(audio_path, language=language, without_timestamps=without_timestamps)\n","                transcription = result[\"text\"]\n","\n","                # Construct output path\n","                output_directory = base_output_directory / Path(root).relative_to(dataset_directory)\n","                os.makedirs(output_directory, exist_ok=True)\n","\n","                # Use the original file's base name for the transcription file\n","                original_base_name = Path(file).stem\n","                t_filename = f\"{original_base_name}_{model_name}_{language}.txt\"\n","                t_path = output_directory / t_filename\n","\n","                with open(t_path, 'w') as text_file:\n","                    text_file.write(transcription)\n","                \n","                print(f\"Transcription completed and saved to {t_path}\\n\")\n","                \n","                \n","def texts_to_organized_mds(api_key, directory_path, temp=0.5, top_p=0.5, top_k=2, max_tokens=4096, prompt=\"\"):\n","    try:\n","        # Configure API with the provided key\n","        genai.configure(api_key=api_key)\n","\n","        # Iterate over all .txt files in the specified directory\n","        for filename in os.listdir(directory_path):\n","            if filename.endswith('.txt'):\n","                s_path = os.path.join(directory_path, filename)\n","                base_name = os.path.splitext(filename)[0]\n","                organized_output = os.path.join(directory_path, f\"{base_name}_organized.md\")\n","\n","                # Read from the text file\n","                print(f\"Reading from text file {s_path}...\")\n","                with open(s_path, 'r') as file:\n","                    transcription = file.read()\n","\n","                # Organize text using the provided API\n","                full_prompt = prompt + \"\\n\\n\" + transcription\n","                model = genai.GenerativeModel(model_name=\"gemini-pro\", \n","                                              generation_config={\"temperature\": temp, \"top_p\": top_p, \"top_k\": top_k, \"max_output_tokens\": max_tokens}, \n","                                              safety_settings=[{\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_ONLY_HIGH\"}, \n","                                                               {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_ONLY_HIGH\"}, \n","                                                               {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_ONLY_HIGH\"}, \n","                                                               {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_ONLY_HIGH\"}])\n","                print(\"Organizing text...\")\n","                response = model.generate_content([full_prompt])\n","\n","                # Save the organized text in markdown format\n","                with open(organized_output, 'w') as file:\n","                    file.write(response.text)\n","                print(f\"Organized text saved to {organized_output}\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","\n","def send_files_via_email(send_from, send_to, subject, message, files, server, port, username, password):\n","    msg = MIMEMultipart()\n","    msg['From'] = send_from\n","    msg['To'] = send_to\n","    msg['Subject'] = subject\n","\n","    msg.attach(MIMEText(message))\n","\n","    for file in files:\n","        part = MIMEBase('application', \"octet-stream\")\n","        with open(file, 'rb') as file_attachment:\n","            part.set_payload(file_attachment.read())\n","        encoders.encode_base64(part)\n","        part.add_header('Content-Disposition', 'attachment; filename=\"{}\"'.format(os.path.basename(file)))\n","        msg.attach(part)\n","\n","    try:\n","        with smtplib.SMTP_SSL(server, port) as smtp:\n","            smtp.login(username, password)\n","            smtp.sendmail(send_from, send_to, msg.as_string())\n","            smtp.quit()\n","\n","        print(\"Email sent successfully!\")\n","        \n","    except Exception as e:\n","        print(f\"Failed to send email: {e}\")\n","        \n","\n","def fetch_sheet_data_as_dataframe(spreadsheet_title, sheet_number):\n","    # Open the spreadsheet by its title\n","    spreadsheet = client.open(spreadsheet_title)\n","    \n","    # Select the sheet by number (1-indexed to match user expectation, so subtract 1 for 0-indexed)\n","    sheet = spreadsheet.get_worksheet(sheet_number - 1)\n","    \n","    # Convert the entire sheet to a DataFrame\n","    df = get_as_dataframe(sheet, evaluate_formulas=True, headers=None, skiprows=0)\n","    \n","    # Drop rows where all elements are nan\n","    df.dropna(how='all', inplace=True)\n","    \n","    # Drop columns where all elements are nan\n","    df.dropna(axis=1, how='all', inplace=True)\n","    \n","    # Reset the index after dropping nan rows\n","    df.reset_index(drop=True, inplace=True)\n","    \n","    return df\n","\n","def assign_values_from_df(df):\n","    values_dict = {}\n","    for _, row in df.iterrows():\n","        if pd.notna(row['Parameters']):\n","            if row['Parameters'] in ['without_timestamp', 'top_k', 'port', 'max_tokens']:\n","                value = int(row['Values'])\n","            elif row['Parameters'] in ['temp', 'top_p']:\n","                value = float(row['Values'])\n","            else:\n","                value = row['Values']\n","            values_dict[row['Parameters']] = value\n","    return values_dict\n","\n","def create_variable():\n","    # String you want to turn into a variable name\n","    string_name = \"variable\"\n","    \n","    # Value you want to assign to the variable\n","    value = \"This is the value of the variable.\"\n","    \n","    # Use the string to create a local variable with the specified value\n","    locals()[string_name] = value\n","    \n","    \n","# Map variable names to their values\n","variable_mapping = {\n","    \"secret_value_0\": secret_value_0,\n","    \"secret_value_1\": secret_value_1,\n","    \"secret_value_2\": secret_value_2,\n","    \"secret_value_3\": secret_value_3,\n","}\n","\n","def get_secret_value(variable_name):\n","    \"\"\"\n","    Returns the value of a secret variable based on its name.\n","\n","    Args:\n","    - variable_name: The name of the variable as a string.\n","\n","    Returns:\n","    - The value of the variable if it exists, otherwise None.\n","    \"\"\"\n","    return variable_mapping.get(variable_name)\n","\n","\n","def check_new_files(df):\n","    # Check if the DataFrame is empty by verifying if it has any rows beyond the title row.\n","    new_files = not df.empty\n","    return new_files\n","\n","\n","def audio_to_md(new_files):\n","    if not new_files:\n","        print(\"There are no new files for transcribing, therefore code terminates.\")\n","        return\n","\n","    # Assuming the existence of all functions called below.\n","    print(\"New files found for transcribing.\")\n","    df2 = fetch_sheet_data_as_dataframe(\"Audio recording to Markdown\", 2)\n","\n","    values_dict = assign_values_from_df(df2)\n","\n","    dataset_directory = values_dict['dataset_directory']\n","\n","    model_name = values_dict['model_name']\n","    language = values_dict['language']\n","    without_timestamp = values_dict['without_timestamp']\n","\n","    api_key = get_secret_value(values_dict['api_key'])\n","    temp = values_dict['temp']\n","    top_p = values_dict['top_p']\n","    top_k = values_dict['top_k']\n","    max_tokens = values_dict['max_tokens']\n","    prompt = values_dict['prompt']\n","\n","    send_from = get_secret_value(values_dict['send_from'])\n","    send_to = values_dict['send_to']\n","    subject = values_dict['subject']\n","    message = values_dict['message']\n","    server = values_dict['server']\n","    port = values_dict['port']\n","    username = send_from  # Since the smtp service is hosted by the same user account.\n","    password = get_secret_value(values_dict['password'])\n","\n","    print(\"\\nParameters fetched.\")\n","\n","    gdown_download(dataset_directory, df1)\n","    \n","    transcribe_audio_files(dataset_directory, model_name, language, without_timestamp)\n","    \n","    texts_to_organized_mds(api_key=api_key, directory_path=f\"{dataset_directory}/transcribed_files\",\n","                           temp=temp, top_p=top_p, top_k=top_k, max_tokens=max_tokens, prompt=prompt)\n","    \n","    directory_path = f\"{dataset_directory}/transcribed_files\"\n","    files = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n","    \n","    send_files_via_email(send_from, send_to, subject, message, files, server, port, username, password)\n","\n","    \n","\n","print()\n","print(\"All functions loaded.\")"]},{"cell_type":"code","execution_count":3,"id":"8b0fede3","metadata":{"execution":{"iopub.execute_input":"2024-03-14T16:11:53.849664Z","iopub.status.busy":"2024-03-14T16:11:53.849354Z","iopub.status.idle":"2024-03-14T16:13:29.896683Z","shell.execute_reply":"2024-03-14T16:13:29.895622Z"},"papermill":{"duration":96.06025,"end_time":"2024-03-14T16:13:29.89882","exception":false,"start_time":"2024-03-14T16:11:53.83857","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["New files found for transcribing.\n","\n","Parameters fetched.\n"]},{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1k2WDfxZZOl4cLF5ACdyMsCT2uRMEnRmC\n","To: /kaggle/working/Test.m4a\n","100%|██████████| 37.4k/37.4k [00:00<00:00, 37.5MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["File 1 has been downloaded and saved to: /kaggle/working/Test.m4a\n","All files with provided names have been successfully downloaded.\n","Loading model 'large-v3'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████████████████████████████████| 2.88G/2.88G [00:44<00:00, 68.7MiB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Transcribing /kaggle/working/Test.m4a with model 'large-v3' in zh...\n","Transcribing...\n","Transcription completed and saved to /kaggle/working/transcribed_files/Test_large-v3_zh.txt\n","\n","Reading from text file /kaggle/working/transcribed_files/Test_large-v3_zh.txt...\n","Organizing text...\n","Organized text saved to /kaggle/working/transcribed_files/Test_large-v3_zh_organized.md\n","Email sent successfully!\n"]}],"source":["df1 = fetch_sheet_data_as_dataframe(\"Audio recording to Markdown\", 1)\n","\n","new_files = check_new_files(df1)\n","\n","audio_to_md(new_files)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30665,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":191.249173,"end_time":"2024-03-14T16:13:32.490233","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-03-14T16:10:21.24106","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}